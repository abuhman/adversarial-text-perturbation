This is the description of the thesis code folder.  The thesis code folder is a backup for the thesis code.  Code in this folder is not functional by itself because it lacks trained models and/or datasets (such as trained CNN and trained Word2Vec) that it uses to function.

Uploaded version is for my personal machine.  Slight differences exist in the Crane version:
    I load a local Word2Vec model on my personal machine rather than the larger Google one for the sake of memory space.  That is why there are two ways to load the Word2Vec model and one is commented out.

The SVM folder contains code for training an SVM.  This is for use with the old version of the code that ran using an SVM classifier rather than CNN.  There is code to train an SVM and code to test its accuracy.  The SVM train code stored here matches the method for choosing features that CNN uses (using features from all words separately instead of trying to combine them).  The perturb_sentence_backup code instead combines features since it was made earlier, so a slight modification would be needed to use these two versions together.

The perturb_sentence folder contains the code to perturb sentences.  Perturb_sentence.py is the version of the perturb_sentence code that works using CNN.  perturb_sentence_backup.py is the old version that works using SVM.  linear_classifier.py is used by both versions of the code in the reverse engineering algorithm to train its own dummy classifier.  perturb_sentence.py needs a trained classifier and the data_helpers.py from the CNN code.

Create_email_datasets folder contains my code for forming new datasets from the large email dataset.  Pickle_emails produces one large pickle (python data storage) file containing the data in all the individual email files.  This makes the data fast and easy to load and manage using Python.  Pickle_to_pos_neg uses the pickle file to create new email datasets of the same format as the mrpolarity data used in the CNN code.  It can create datasets of any given size selected by the user up to the total size of the email dataset.  Each new dataset is randomized in terms of which emails are selected to populate it, so two datasets of the same size created by this code will not be identical.

CNN folder contains code for training and evaluating the CNN.  It is based on the CNN code from online.  Currently the train file cuts off training early using an exit() command at the end of the file, which I use for creating CNNs quickly for debugging.  To get the fully trained dataset, the exit() command should be removed.
